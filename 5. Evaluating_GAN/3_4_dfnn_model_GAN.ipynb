{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Deep Feedforward Neural Network (w/ GAN data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Load In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases + conrols df\n",
    "df = pd.read_csv('/project/ds6050-soa2wg/team_lambda_II/ASD_DSM_CasesvsControls.csv', sep = ',')\n",
    "\n",
    "# obtain paths for all images\n",
    "images_paths_f_case = list(df.query(\"SEX_ == 'Female' & DX_Control == 'Autism'\")['PATH'])\n",
    "images_paths_f_control = list(df.query(\"SEX_ == 'Female' & DX_Control == 'Control'\")['PATH'])\n",
    "images_paths_m_case = list(df.query(\"SEX_ == 'Male' & DX_Control == 'Autism'\")['PATH'])\n",
    "images_paths_m_control = list(df.query(\"SEX_ == 'Male' & DX_Control == 'Control'\")['PATH'])\n",
    "\n",
    "# GAN\n",
    "gan_data_m = np.load('Ellen Exploratory (Will Delete When Done)/gan_pos_female_ep500_cs3000_si50.npy')\n",
    "gan_data_f = np.load('gan_pos_male_ep500_cs3000_si50.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data_cases = np.concatenate((gan_data_f, gan_data_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases = len(images_paths_f_case) + len(images_paths_m_case) + gan_data_m.shape[0] + gan_data_f.shape[0]\n",
    "total_controls = len(images_paths_f_control ) + len(images_paths_m_control) #+ gan_control_f.shape[0]\n",
    "# print out number of participants per category\n",
    "print('There are {} female cases'.format(str(len(images_paths_f_case) + gan_data_f.shape[0])))\n",
    "print('---------------------------------------')\n",
    "print('There are {} female controls'.format(str(len(images_paths_f_control))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} male cases'.format(str(len(images_paths_m_case) + gan_data_m.shape[0])))\n",
    "print('---------------------------------------')\n",
    "print('There are {} male controls'.format(str(len(images_paths_m_control))))\n",
    "print('---------------------------------------')\n",
    "print(f'There are {total_cases} total cases and {total_controls} total controls! {total_controls + total_cases} participants in total')\n",
    "# make one giant list\n",
    "images_paths = images_paths_f_case  + images_paths_f_control + images_paths_m_case + images_paths_m_control\n",
    "\n",
    "num_im = len(images_paths)\n",
    "image_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22 female cases\n",
      "---------------------------------------\n",
      "There are 61 female controls\n",
      "---------------------------------------\n",
      "There are 124 male cases\n",
      "---------------------------------------\n",
      "There are 184 male controls\n",
      "---------------------------------------\n",
      "There are 146 total cases and 245 total controls! 391 participants in total\n"
     ]
    }
   ],
   "source": [
    "final_list = [] # create image array from paths\n",
    "for path in images_paths:\n",
    "    try: \n",
    "        img = nib.load(path)\n",
    "        image_data = img.get_fdata()\n",
    "        image_array.append(image_data)\n",
    "        final_list.append(path)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "image_array = np.asarray(image_array).astype('float32')\n",
    "image_array = np.vstack((image_array,gan_data_cases))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491, 61, 73, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    245\n",
       "1    146\n",
       "Name: DX_GROUP, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno = df[['FILE_ID', 'DX_GROUP']]\n",
    "pheno_array = np.array(pheno['DX_GROUP'])\n",
    "pheno_array = np.where(pheno_array == 2, 0, pheno_array) # 0 = control, 1 = dx\n",
    "# distribution\n",
    "df['DX_GROUP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan_pheno\n",
    "gan_pheno_cases = np.ones((gan_data_cases.shape[0],), dtype=int)\n",
    "all_pheno = np.concatenate((pheno_array, gan_pheno_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and holdout split\n",
    "x_train, x_val, y_train, y_val = train_test_split(image_array, all_pheno, test_size = 0.15, random_state = 654)\n",
    "\n",
    "#training and testing split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.25, random_state = 654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f935c334940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[15][48].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "batch_size = 16\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "#     .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_test))\n",
    "#    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Highest performing DFNN architecture from Mellema 2022 ** Best Performing with GAN data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense_model(width=61, height=73, depth=61):\n",
    "    \"\"\"Build a Highest performing Dense FNN neural network model from Mellema 2022.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "    \n",
    "    x = layers.Dense(6,kernel_regularizer=tf.keras.regularizers.l2(0.0001))(inputs)\n",
    "    x = layers.Dense(units=64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.13)(x)\n",
    "    x = layers.Dense(units=64, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"DFNN\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = Dense_model(width=61, height=73, depth=61)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.0001\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# Compile model.\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    " #   \"3d_image_classification_Cxa_DFNN.h5\", save_best_only=True\n",
    "#)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", patience=10)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 50\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    callbacks=early_stopping_cb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the weights\n",
    "# model.save_weights('DFNN_DoubleActuals_mod1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Load best weights.\n",
    "# model.load_weights(\"DFNN_DoubleActuals_mod1.h5\")\n",
    "prediction = model.predict(np.expand_dims(x_test[0], axis=0))[0]\n",
    "print(prediction)\n",
    "scores = [1 - prediction[0], prediction[0]]\n",
    "\n",
    "class_names = [\"normal\", \"abnormal\"]\n",
    "for score, name in zip(scores, class_names):\n",
    "    print(\n",
    "    \"This model is %.2f percent confident that CT scan is %s\"\n",
    "    % ((100 * score), name))\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion of training data that's positive\n",
    "sum(y_train) / len(y_train)\n",
    "\n",
    "#proportion of holdout data that's positive\n",
    "(sum(y_val) / len(y_val))\n",
    "\n",
    "#evaluate on the holdout data\n",
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "preds = model.predict(x_val)\n",
    "\n",
    "preds = np.where(preds > .5, 1,0)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_val, preds))\n",
    "cm = confusion_matrix(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = model.predict(x_val).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_val, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Model (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import ImageFont\n",
    "# font = ImageFont.truetype(\"Arial.ttf\", 16)\n",
    "# visualkeras.layered_view(model, legend=True,font = font, to_file='DFNN1arch_gan.png')  # font is optional!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build a Highest performing Dense FNN neural network model from Mellema 2022 with modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense_model(width=61, height=73, depth=61):\n",
    "    \"\"\"Build a Highest performing Dense FNN neural network model from Mellema 2022 with modifications.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))  \n",
    "     \n",
    "    x = layers.Dense(6,kernel_regularizer=tf.keras.regularizers.l2(0.0001))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.13)(x)\n",
    "    x = layers.Dense(units=64, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"DFNN\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = Dense_model(width=61, height=73, depth=61)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.95, staircase=True)\n",
    "\n",
    "# Compile model.\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    " #   \"3d_image_classification_Cxa_adamDFNN.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", patience=15)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 50\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    callbacks=early_stopping_cb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on the holdout data\n",
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "preds = model.predict(x_val)\n",
    "\n",
    "preds = np.where(preds > .5, 1,0)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_val, preds))\n",
    "cm = confusion_matrix(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = model.predict(x_val).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_val, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Model (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Complex Highest performing Dense FNN neural network model from Mellema 2022 with modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense_model(width=61, height=73, depth=61):\n",
    "    \"\"\"Build a complex Highest performing Dense FNN neural network model from Mellema 2022.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "    \n",
    "    x = layers.Dense(units=128, activation=\"relu\", kernel_regularizer = keras.regularizers.L2(0.00011))(inputs)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dropout(0.18)(x)\n",
    "    x = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.18)(x)\n",
    "    x = layers.Dense(units=64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.18)(x)\n",
    "    x = layers.Dense(units=42, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"DFNN_complex\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = Dense_model(width=61, height=73, depth=61)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=10000, decay_rate=0.96, staircase=True)\n",
    "\n",
    "# Compile model.\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    " #   \"3d_image_classification_Cxa_adamDFNN.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", patience=15)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 50\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping_cb],\n",
    ")\n",
    "\n",
    "# # Train the model, doing validation at the end of each epoch\n",
    "# epochs = 50\n",
    "# model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=validation_dataset,\n",
    "#     epochs=epochs,\n",
    "#     shuffle=True,\n",
    "#     callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on the holdout data\n",
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "preds = model.predict(x_val)\n",
    "\n",
    "preds = np.where(preds > .5, 1,0)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_val, preds))\n",
    "cm = confusion_matrix(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = model.predict(x_val).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_val, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Model (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.8.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
