{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Networks\n",
    " \n",
    "May 2, 2022\n",
    "\n",
    "_I think this is going to be my last one. Using Keras, this code will generate new celebrity faces._\n",
    "\n",
    "_Update: This code didn't work for me. But this tutorial imparted the idea that GANs are selecting from e.g. 116412-dimensional space and each point is a face and we're trying to maximize the probability that \n",
    "\n",
    "https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VAEs typically produce blurry and non-photorealistic faces. This is a motivation to built Generative Adversarial Networks (GANs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The celebrity faces are 218px height, 178px width with 3 color channels. Therefore each vector is 116412-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116412"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "218 * 178 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Training a DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Discriminator\n",
    "\n",
    "from keras.layers import Conv2D, BatchNormalization, Input, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# function for building the discriminator layers\n",
    "def build_discriminator(start_filters, spatial_dim, filter_size):\n",
    "    \n",
    "    # function for building a CNN block for downsampling the image\n",
    "    def add_discriminator_block(x, filters, filter_size):\n",
    "      x = Conv2D(filters, filter_size, padding='same')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = Conv2D(filters, filter_size, padding='same', strides=2)(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = LeakyReLU(0.3)(x)\n",
    "      return x\n",
    "    \n",
    "    # input is an image with shape spatial_dim x spatial_dim and 3 channels\n",
    "    inp = Input(shape=(spatial_dim, spatial_dim, 3))\n",
    "\n",
    "    # design the discrimitor to downsample the image 4x\n",
    "    x = add_discriminator_block(inp, start_filters, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 2, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 4, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 8, filter_size)\n",
    "    \n",
    "    # average and return a binary output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Generator\n",
    "#from keras.layers import Deconvolution2D, Reshape\n",
    "from keras.layers import Conv2DTranspose, Reshape\n",
    "\n",
    "\n",
    "def build_generator(start_filters, filter_size, latent_dim):\n",
    "  \n",
    "  # function for building a CNN block for upsampling the image\n",
    "  def add_generator_block(x, filters, filter_size):\n",
    "      x = Conv2DTranspose(filters, filter_size, strides=2, padding='same')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = LeakyReLU(0.3)(x)\n",
    "      return x\n",
    "\n",
    "  # input is a noise vector \n",
    "  inp = Input(shape=(latent_dim,))\n",
    "\n",
    "  # projection of the noise vector into a tensor with \n",
    "  # same shape as last conv layer in discriminator\n",
    "  x = Dense(4 * 4 * (start_filters * 8), input_dim=latent_dim)(inp)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Reshape(target_shape=(4, 4, start_filters * 8))(x)\n",
    "\n",
    "  # design the generator to upsample the image 4x\n",
    "  x = add_generator_block(x, start_filters * 4, filter_size)\n",
    "  x = add_generator_block(x, start_filters * 2, filter_size)\n",
    "  x = add_generator_block(x, start_filters, filter_size)\n",
    "  x = add_generator_block(x, start_filters, filter_size)    \n",
    "\n",
    "  # turn the output into a 3D tensor, an image with 3 channels \n",
    "  x = Conv2D(3, kernel_size=5, padding='same', activation='tanh')(x)\n",
    "  \n",
    "  return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2048)              206848    \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 2048)             8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 8, 8, 64)         204864    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  (None, 16, 16, 32)       51232     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 16, 16, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  (None, 32, 32, 16)       12816     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 32, 32, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_11 (Conv2D  (None, 64, 64, 16)       6416      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 64, 64, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 64, 64, 16)        0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 64, 64, 3)         1203      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,083\n",
      "Trainable params: 487,731\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 64, 64, 16)        1216      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 64, 64, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 32, 32, 16)        6416      \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 32, 32, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 32, 32, 32)        12832     \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 16, 16, 32)        25632     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 16, 16, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 16, 16, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 8, 8, 64)          102464    \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 8, 8, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 4, 4, 128)         409728    \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 128)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 816,529\n",
      "Trainable params: 0\n",
      "Non-trainable params: 816,529\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_5 (Functional)        (None, 64, 64, 3)         492083    \n",
      "                                                                 \n",
      " model_4 (Functional)        (None, 1)                 816529    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,308,612\n",
      "Trainable params: 487,731\n",
      "Non-trainable params: 820,881\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## The GAN\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "# load celebrity images attributes\n",
    "df_celeb = pd.read_csv('list_attr_celeba.csv')\n",
    "TOTAL_SAMPLES = df_celeb.shape[0]\n",
    "\n",
    "# we will downscale the images\n",
    "SPATIAL_DIM = 64 \n",
    "# size of noise vector\n",
    "LATENT_DIM_GAN = 100 \n",
    "# filter size in conv layer\n",
    "FILTER_SIZE = 5\n",
    "# number of filters in conv layer\n",
    "NET_CAPACITY = 16\n",
    "# batch size\n",
    "BATCH_SIZE_GAN = 32\n",
    "# interval for displaying generated images\n",
    "PROGRESS_INTERVAL = 80 \n",
    "# directory for storing generated images\n",
    "ROOT_DIR = 'visualization'\n",
    "if not os.path.isdir(ROOT_DIR):\n",
    "    os.mkdir(ROOT_DIR)\n",
    "    \n",
    "\n",
    "\n",
    "def construct_models(verbose=False):\n",
    "    ### discriminator\n",
    "    discriminator = build_discriminator(NET_CAPACITY, SPATIAL_DIM, FILTER_SIZE)\n",
    "    # compile discriminator\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002), metrics=['mae'])\n",
    "\n",
    "    ### generator\n",
    "    # do not compile generator\n",
    "    generator = build_generator(NET_CAPACITY, FILTER_SIZE, LATENT_DIM_GAN)\n",
    "\n",
    "    ### DCGAN \n",
    "    gan = Sequential()\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "    discriminator.trainable = False \n",
    "    gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002), metrics=['mae'])\n",
    "\n",
    "    if verbose: \n",
    "        generator.summary()\n",
    "        discriminator.summary()\n",
    "        gan.summary()\n",
    "        \n",
    "    return generator, discriminator, gan\n",
    "  \n",
    "generator_celeb, discriminator_celeb, gan_celeb = construct_models(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_real_celebrity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m GEN_UPDATES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# function for training a GAN\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_training\u001b[39m(generator, discriminator, gan, df\u001b[38;5;241m=\u001b[39mdf_celeb, start_it\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, \n\u001b[0;32m---> 16\u001b[0m                  get_real_images\u001b[38;5;241m=\u001b[39m\u001b[43mget_real_celebrity\u001b[49m):\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m   \u001b[38;5;66;03m# helper function for selecting 'size' real images\u001b[39;00m\n\u001b[1;32m     19\u001b[0m   \u001b[38;5;66;03m# and downscaling them to lower dimension SPATIAL_DIM\u001b[39;00m\n\u001b[1;32m     20\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_real_celebrity\u001b[39m (df, size, total):\n\u001b[1;32m     21\u001b[0m       cur_files \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m:size]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_real_celebrity' is not defined"
     ]
    }
   ],
   "source": [
    "## GAN Training\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    " \n",
    "# number of discriminator updates per alternating training iteration\n",
    "DISC_UPDATES = 1  \n",
    "# number of generator updates per alternating training iteration\n",
    "GEN_UPDATES = 1 \n",
    "\n",
    "# function for training a GAN\n",
    "def run_training(generator, discriminator, gan, df=df_celeb, start_it=0, num_epochs=1000, \n",
    "                 get_real_images=get_real_celebrity):\n",
    "\n",
    "  # helper function for selecting 'size' real images\n",
    "  # and downscaling them to lower dimension SPATIAL_DIM\n",
    "  def get_real_celebrity (df, size, total):\n",
    "      cur_files = df.sample(frac=1).iloc[0:size]\n",
    "      X = np.empty(shape=(size, SPATIAL_DIM, SPATIAL_DIM, 3))\n",
    "      for i in range(0, size):\n",
    "          file = cur_files.iloc[i]\n",
    "          img_uri = 'img_align_celeba/' + file.image_id\n",
    "          img = cv2.imread(img_uri)\n",
    "          img = cv2.resize(img, (SPATIAL_DIM, SPATIAL_DIM))\n",
    "          img = np.flip(img, axis=2)\n",
    "          img = img.astype(np.float32) / 127.5 - 1.0\n",
    "          X[i] = img\n",
    "      return X\n",
    "  \n",
    "  # list for storing loss\n",
    "  avg_loss_discriminator = []\n",
    "  avg_loss_generator = []\n",
    "  total_it = start_it\n",
    "\n",
    "  # main training loop\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "      # alternating training loop\n",
    "      loss_discriminator = []\n",
    "      loss_generator = []\n",
    "      for it in range(200): \n",
    "\n",
    "          #### Discriminator training loop ####\n",
    "          for i in range(DISC_UPDATES): \n",
    "              # select a random set of real images\n",
    "              imgs_real = get_real_images(df, BATCH_SIZE_GAN, TOTAL_SAMPLES)\n",
    "              # generate a set of random noise vectors\n",
    "              noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
    "              # generate a set of fake images using the generator\n",
    "              imgs_fake = generator.predict(noise)\n",
    "              # train the discriminator on real images with label 1\n",
    "              d_loss_real = discriminator.train_on_batch(imgs_real, np.ones([BATCH_SIZE_GAN]))[1]\n",
    "              # train the discriminator on fake images with label 0\n",
    "              d_loss_fake = discriminator.train_on_batch(imgs_fake, np.zeros([BATCH_SIZE_GAN]))[1]\n",
    "\n",
    "          # display some fake images for visual control of convergence\n",
    "          if total_it % PROGRESS_INTERVAL == 0:\n",
    "              plt.figure(figsize=(5,2))\n",
    "              num_vis = min(BATCH_SIZE_GAN, 5)\n",
    "              imgs_real = get_real_images(df, num_vis, TOTAL_SAMPLES)\n",
    "              noise = np.random.randn(num_vis, LATENT_DIM_GAN)\n",
    "              imgs_fake = generator.predict(noise)\n",
    "              for obj_plot in [imgs_fake, imgs_real]:\n",
    "                  plt.figure(figsize=(num_vis * 3, 3))\n",
    "                  for b in range(num_vis):\n",
    "                      disc_score = float(discriminator.predict(np.expand_dims(obj_plot[b], axis=0))[0])\n",
    "                      plt.subplot(1, num_vis, b + 1)\n",
    "                      plt.title(str(round(disc_score, 3)))\n",
    "                      plt.imshow(obj_plot[b] * 0.5 + 0.5) \n",
    "                  if obj_plot is imgs_fake:\n",
    "                      plt.savefig(os.path.join(ROOT_DIR, str(total_it).zfill(10) + '.jpg'), format='jpg', bbox_inches='tight')\n",
    "                  plt.show()  \n",
    "\n",
    "          #### Generator training loop ####\n",
    "          loss = 0\n",
    "          y = np.ones([BATCH_SIZE_GAN, 1]) \n",
    "          for j in range(GEN_UPDATES):\n",
    "              # generate a set of random noise vectors\n",
    "              noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
    "              # train the generator on fake images with label 1\n",
    "              loss += gan.train_on_batch(noise, y)[1]\n",
    "\n",
    "          # store loss\n",
    "          loss_discriminator.append((d_loss_real + d_loss_fake) / 2.)        \n",
    "          loss_generator.append(loss / GEN_UPDATES)\n",
    "          total_it += 1\n",
    "\n",
    "      # visualize loss\n",
    "      clear_output(True)\n",
    "      print('Epoch', epoch)\n",
    "      avg_loss_discriminator.append(np.mean(loss_discriminator))\n",
    "      avg_loss_generator.append(np.mean(loss_generator))\n",
    "      plt.plot(range(len(avg_loss_discriminator)), avg_loss_discriminator)\n",
    "      plt.plot(range(len(avg_loss_generator)), avg_loss_generator)\n",
    "      plt.legend(['discriminator loss', 'generator loss'])\n",
    "      plt.show()\n",
    "\n",
    "  return generator, discriminator, gan\n",
    "\n",
    "generator_celeb, discriminator_celeb, gan_celeb = run_training(generator_celeb, \n",
    "                                                               discriminator_celeb, \n",
    "                                                               gan_celeb, \n",
    "                                                               num_epochs=500, \n",
    "                                                               df=df_celeb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.8.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
