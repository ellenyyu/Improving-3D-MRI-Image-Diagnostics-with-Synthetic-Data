{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63564a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nibabel in /home/dsh7pd/.local/lib/python3.9/site-packages (3.2.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.9/site-packages (from nibabel) (21.3)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.9/site-packages (from nibabel) (1.22.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from nibabel) (58.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging>=14.3->nibabel) (3.0.7)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-api-python-client in /home/dsh7pd/.local/lib/python3.9/site-packages (2.46.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/dsh7pd/.local/lib/python3.9/site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.9/site-packages (from google-api-python-client) (2.6.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/dsh7pd/.local/lib/python3.9/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /home/dsh7pd/.local/lib/python3.9/site-packages (from google-api-python-client) (0.20.4)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/dsh7pd/.local/lib/python3.9/site-packages (from google-api-python-client) (2.7.3)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.19.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /home/dsh7pd/.local/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.56.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.9/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2021.10.8)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-api-core in /home/dsh7pd/.local/lib/python3.9/site-packages (2.7.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /home/dsh7pd/.local/lib/python3.9/site-packages (from google-api-core) (1.56.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.9/site-packages (from google-api-core) (3.19.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/site-packages (from google-api-core) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.9/site-packages (from google-api-core) (2.6.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core) (4.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core) (5.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core) (1.26.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Load dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "!pip install nibabel\n",
    "import nibabel as nib\n",
    "\n",
    "!pip install --upgrade google-api-python-client\n",
    "!pip install --upgrade google-api-core\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import googleapiclient.discovery \n",
    "\n",
    "#!pip install nibabel\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c57da2",
   "metadata": {},
   "source": [
    "# Convert saved model from .h5 format to tensorflow savedmodel format (only needs to be done once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa2865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 61, 73, 61, 1)]   0         \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 61, 73, 61, 1)    3         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 61, 73, 61, 64)    1792      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 30, 36, 30, 64)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 36, 30, 64)   256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 30, 36, 30, 64)    110656    \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 15, 18, 15, 64)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 18, 15, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 15, 18, 15, 128)   221312    \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 7, 9, 7, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 9, 7, 128)     512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 7, 9, 7, 128)      442496    \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 3, 4, 3, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 3, 4, 3, 128)     512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_average_pooling3d (G  (None, 128)              0         \n",
      " lobalAveragePooling3D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                2064      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 779,876\n",
      "Trainable params: 779,105\n",
      "Non-trainable params: 771\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 17:39:30.739620: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-01 17:39:33.122924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 198 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7\n",
      "2022-05-01 17:39:33.128037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10643 MB memory:  -> device: 1, name: Tesla K80, pci bus id: 0000:85:00.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "#Reconstruct the same model architecture as the base model trained earlier\n",
    "def get_model(width=61, height=73, depth=61):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "    \n",
    "    x = layers.Normalization(axis=None)(inputs) #ADDED NORMALIZATION LAYER\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=16, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=61, height=73, depth=61)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0cc52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model weights so that w can export to protocolbuffer format\n",
    "model.load_weights(\"3d_image_classification_Cxa.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe678c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 17:39:34.106190: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: base_ABIDE_model/0001/assets\n"
     ]
    }
   ],
   "source": [
    "#Save model as protocolbuffer\n",
    "model_version = \"0001\"\n",
    "model_name = \"base_ABIDE_model\"\n",
    "model_path = os.path.join(model_name, model_version)\n",
    "tf.saved_model.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e5ea3",
   "metadata": {},
   "source": [
    "# After saving the model, it was uploaded and configured on GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea67ff",
   "metadata": {},
   "source": [
    "# Read in our data to test the model with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09d0e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/project/ds6050-soa2wg/team_lambda_II/ASD_DSM_CasesvsControls.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5827b919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22 female cases\n",
      "---------------------------------------\n",
      "There are 61 female controls\n",
      "---------------------------------------\n",
      "There are 124 male cases\n",
      "---------------------------------------\n",
      "There are 184 male controls\n",
      "---------------------------------------\n",
      "There are 146 total cases and 245 total controls! 391 participants in total\n"
     ]
    }
   ],
   "source": [
    "# obtain paths for all images\n",
    "images_paths_f_case = list(df.query(\"SEX_ == 'Female' & DX_Control == 'Autism'\")['PATH'])\n",
    "images_paths_f_control = list(df.query(\"SEX_ == 'Female' & DX_Control == 'Control'\")['PATH'])\n",
    "images_paths_m_case = list(df.query(\"SEX_ == 'Male' & DX_Control == 'Autism'\")['PATH'])\n",
    "images_paths_m_control = list(df.query(\"SEX_ == 'Male' & DX_Control == 'Control'\")['PATH'])\n",
    "\n",
    "total_cases = len(images_paths_f_case) + len(images_paths_m_case)\n",
    "total_controls = len(images_paths_f_control ) + len(images_paths_m_control)\n",
    "# print out number of participants per category\n",
    "print('There are {} female cases'.format(str(len(images_paths_f_case))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} female controls'.format(str(len(images_paths_f_control))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} male cases'.format(str(len(images_paths_m_case))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} male controls'.format(str(len(images_paths_m_control))))\n",
    "print('---------------------------------------')\n",
    "print(f'There are {total_cases} total cases and {total_controls} total controls! {total_controls + total_cases} participants in total')\n",
    "# make one giant list\n",
    "images_paths = images_paths_f_case  + images_paths_f_control + images_paths_m_case + images_paths_m_control\n",
    "\n",
    "num_im = len(images_paths)\n",
    "image_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a59bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = [] # create image array from paths\n",
    "for path in images_paths:\n",
    "    try: \n",
    "        img = nib.load(path)\n",
    "        image_data = img.get_fdata()\n",
    "        image_array.append(image_data)\n",
    "        final_list.append(path)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "image_array = np.expand_dims(np.asarray(image_array), axis=4).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "96e8cf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 61, 73, 61, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9a7ea77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    245\n",
       "1    146\n",
       "Name: DX_GROUP, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno = df[['FILE_ID', 'DX_GROUP']]\n",
    "pheno_array = np.array(pheno['DX_GROUP'])\n",
    "pheno_array = np.where(pheno_array == 2, 0, pheno_array)\n",
    "# distribution\n",
    "df['DX_GROUP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7bf5bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and holdout split\n",
    "x_train, x_val, y_train, y_val = train_test_split(image_array, pheno_array, test_size = 0.15, random_state = 654)\n",
    "\n",
    "#training and testing split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.25, random_state = 654)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620ef6d",
   "metadata": {},
   "source": [
    "# Set up the google cloud API to make predictions from our hosted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "75406379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the environment variable for authentication unsing the token file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"cryptic-album-348921-0ae294441f93.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fc58ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the google cloud identifiers for the hosted model\n",
    "project_id = \"cryptic-album-348921\"\n",
    "model_id = \"DS6050_Lambda_base_model\"\n",
    "region = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fe096960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "#Function to make predictions using our hosted model\n",
    "#https://cloud.google.com/ai-platform/prediction/docs/online-predict#requesting_predictions\n",
    "\n",
    "def predict_json(project, region, model, instances, version=None):\n",
    "    \"\"\"Send json data to a deployed model for prediction.\n",
    "\n",
    "    Args:\n",
    "        project (str): project where the Cloud ML Engine Model is deployed.\n",
    "        region (str): regional endpoint to use; set to None for ml.googleapis.com\n",
    "        model (str): model name.\n",
    "        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n",
    "            your deployed model expects as inputs. Values should be datatypes\n",
    "            convertible to Tensors, or (potentially nested) lists of datatypes\n",
    "            convertible to tensors.\n",
    "        version: str, version of the model to target.\n",
    "    Returns:\n",
    "        Mapping[str: any]: dictionary of prediction results defined by the\n",
    "            model.\n",
    "    \"\"\"\n",
    "    # Create the ML Engine service object.\n",
    "    # To authenticate set the environment variable\n",
    "    # GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n",
    "    \n",
    "    instances = instances.tolist()\n",
    "    \n",
    "    prefix = \"{}-ml\".format(region) if region else \"ml\"\n",
    "    api_endpoint = \"https://{}.googleapis.com\".format(prefix)\n",
    "    client_options = ClientOptions(api_endpoint=api_endpoint)\n",
    "    service = googleapiclient.discovery.build(\n",
    "        'ml', 'v1', client_options=client_options)\n",
    "    name = 'projects/{}/models/{}'.format(project, model)\n",
    "\n",
    "    if version is not None:\n",
    "        name += '/versions/{}'.format(version)\n",
    "\n",
    "    response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "\n",
    "    return response['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21790107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.957655191]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the predict function to call our model and output the probability of a positive case\n",
    "predict_json(project = project_id, \n",
    "             region = region, \n",
    "             model = model_id, \n",
    "             instances = x_test[0], \n",
    "             version=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19d6049d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the actual label of the observation\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf736b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.8.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
