{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN\n",
    "\n",
    "May 1, 2022 \n",
    "\n",
    "_Implementing DC GAN for larger images_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nibabel\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/project/ds6050-soa2wg/team_lambda_II/ASD_DSM_CasesvsControls.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain paths for all images\n",
    "images_paths_f_case = list(df.query(\"SEX_ == 'Female' & DX_Control == 'Autism'\")['PATH'])\n",
    "images_paths_f_control = list(df.query(\"SEX_ == 'Female' & DX_Control == 'Control'\")['PATH'])\n",
    "images_paths_m_case = list(df.query(\"SEX_ == 'Male' & DX_Control == 'Autism'\")['PATH'])\n",
    "images_paths_m_control = list(df.query(\"SEX_ == 'Male' & DX_Control == 'Control'\")['PATH'])\n",
    "\n",
    "total_cases = len(images_paths_f_case) + len(images_paths_m_case)\n",
    "total_controls = len(images_paths_f_control ) + len(images_paths_m_control)\n",
    "# print out number of participants per category\n",
    "print('There are {} female cases'.format(str(len(images_paths_f_case))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} female controls'.format(str(len(images_paths_f_control))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} male cases'.format(str(len(images_paths_m_case))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} male controls'.format(str(len(images_paths_m_control))))\n",
    "print('---------------------------------------')\n",
    "print(f'There are {total_cases} total cases and {total_controls} total controls! {total_controls + total_cases} participants in total')\n",
    "# make one giant list\n",
    "#images_paths = images_paths_f_case  + images_paths_f_control + images_paths_m_case + images_paths_m_control\n",
    "\n",
    "# positive cases only\n",
    "#images_paths = images_paths_f_case + images_paths_m_case\n",
    "\n",
    "# female only (testing purposes)\n",
    "images_paths = images_paths_f_case\n",
    "\n",
    "# male only (testing purposes)\n",
    "images_paths = images_paths_m_case\n",
    "\n",
    "num_im = len(images_paths)\n",
    "image_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = [] # create image array from paths\n",
    "for path in images_paths:\n",
    "    try: \n",
    "        img = nib.load(path)\n",
    "        image_data = img.get_fdata()\n",
    "        image_array.append(image_data)\n",
    "        final_list.append(path)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "image_array = np.asarray(image_array).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 5 of the 391 images\n",
    "for i in image_array[:5]: \n",
    "    plt.imshow(i[:,:,30])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #??? Ask Chelsea about this line of code. How is this phenotype data? \n",
    "# pheno = df[['FILE_ID', 'DX_GROUP']]\n",
    "# pheno_array = np.array(pheno['DX_GROUP'])\n",
    "# pheno_array = np.where(pheno_array == 2, 0, pheno_array) # This is a function to replace 2 with 0\n",
    "# # distribution\n",
    "# df['DX_GROUP'].value_counts()\n",
    "\n",
    "# I think she means for this to be y label data right?\n",
    "y = df[['FILE_ID', 'DSM_IV_TR', 'SEX_']] # 1 means Autism, 0 means Control\n",
    "#y_array = np.array(y['DSM_IV_TR'])\n",
    "\n",
    "#positive only \n",
    "#y_array = np.array(y.query(\"DSM_IV_TR == 1\")[\"DSM_IV_TR\"])\n",
    "\n",
    "# female only (testing purposes)\n",
    "y_array = np.array(y.query(\"DSM_IV_TR == 1 & SEX_ == 'Female'\")[\"DSM_IV_TR\"])\n",
    "\n",
    "# male only (testing purposes)\n",
    "y_array = np.array(y.query(\"DSM_IV_TR == 1 & SEX_ == 'Male'\")[\"DSM_IV_TR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#x_train, x_test, y_train, y_test = train_test_split(image_array, pheno_array, test_size = 0.25, random_state = 44)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mimage_array\u001b[49m, y_array, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m44\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_array' is not defined"
     ]
    }
   ],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(image_array, pheno_array, test_size = 0.25, random_state = 44)\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_array, y_array, test_size = 0.25, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking imbalance of training set. Below is how you do value counts for np array. \n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# first attempt at plotting \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#plt.imshow(x_train[:,:,30])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#TypeError: Invalid shape (293, 61, 61) for image data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#borrowing my other code for plotting\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mx_train\u001b[49m[:\u001b[38;5;241m1\u001b[39m]: \n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(i[\u001b[38;5;241m30\u001b[39m,:,:])\n\u001b[1;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# first attempt at plotting \n",
    "#plt.imshow(x_train[:,:,30])\n",
    "#TypeError: Invalid shape (293, 61, 61) for image data\n",
    "\n",
    "#borrowing my other code for plotting\n",
    "for i in x_train[:1]: \n",
    "    plt.imshow(i[30,:,:])\n",
    "    plt.show()\n",
    "    \n",
    "# this code also works\n",
    "plt.imshow(x_train[0][30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_preprocessing(volume, label):\n",
    "#     \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "#     # Rotate volume\n",
    "#     volume = rotate(volume)\n",
    "#     volume = tf.expand_dims(volume, axis=3) #??? Is the extra channel by how much the image was rotated? Ask Dylan.\n",
    "#     return volume, label\n",
    "\n",
    "# def validation_preprocessing(volume, label):\n",
    "#     \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "#     volume = tf.expand_dims(volume, axis=3)\n",
    "#     return volume, label\n",
    "\n",
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1 #return the integer of the division \n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image[30,:,:])\n",
    "        #plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # This is cool, double-check the documentation for this??? \n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test)) #??? Should we have equal number of each class in our training data? \n",
    "\n",
    "batch_size = 16\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train)) # ??? shuffle dubplicates right? Or does it only shuffle? Double-check\n",
    "#     .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE) # ??? I thought prefetch was for speed purposes. What is this tf.data.AUTOTUNE. Double-check. \n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_test))\n",
    "#    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
    "    keras.layers.Reshape([7, 7, 128]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\",\n",
    "                                 activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\",\n",
    "                                 activation=\"tanh\")\n",
    "])\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2),\n",
    "                        input_shape=[28, 28, 1]),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dcgan = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.8.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
