{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN\n",
    "\n",
    "_Implementing DC GAN for larger images_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 19:55:45.971352: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-04 19:55:45.971394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (udc-aw34-21c0): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'IS_COLAB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GPU was detected. LSTMs and CNNs can be very slow without a GPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mIS_COLAB\u001b[49m:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGo to Runtime > Change runtime and select a GPU hardware accelerator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m IS_KAGGLE:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IS_COLAB' is not defined"
     ]
    }
   ],
   "source": [
    "#!pip install nibabel\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/project/ds6050-soa2wg/team_lambda_II/ASD_DSM_CasesvsControls.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain paths for all images\n",
    "images_paths_f_case = list(df.query(\"SEX_ == 'Female' & DX_Control == 'Autism'\")['PATH'])\n",
    "images_paths_f_control = list(df.query(\"SEX_ == 'Female' & DX_Control == 'Control'\")['PATH'])\n",
    "images_paths_m_case = list(df.query(\"SEX_ == 'Male' & DX_Control == 'Autism'\")['PATH'])\n",
    "images_paths_m_control = list(df.query(\"SEX_ == 'Male' & DX_Control == 'Control'\")['PATH'])\n",
    "\n",
    "total_cases = len(images_paths_f_case) + len(images_paths_m_case)\n",
    "total_controls = len(images_paths_f_control ) + len(images_paths_m_control)\n",
    "# print out number of participants per category\n",
    "print('There are {} female cases'.format(str(len(images_paths_f_case))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} female controls'.format(str(len(images_paths_f_control))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} male cases'.format(str(len(images_paths_m_case))))\n",
    "print('---------------------------------------')\n",
    "print('There are {} male controls'.format(str(len(images_paths_m_control))))\n",
    "print('---------------------------------------')\n",
    "print(f'There are {total_cases} total cases and {total_controls} total controls! {total_controls + total_cases} participants in total')\n",
    "# make one giant list\n",
    "#images_paths = images_paths_f_case  + images_paths_f_control + images_paths_m_case + images_paths_m_control\n",
    "\n",
    "# positive cases only\n",
    "#images_paths = images_paths_f_case + images_paths_m_case\n",
    "\n",
    "# female only (testing purposes)\n",
    "images_paths = images_paths_f_case\n",
    "\n",
    "# male only (testing purposes)\n",
    "images_paths = images_paths_m_case\n",
    "\n",
    "num_im = len(images_paths)\n",
    "image_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = [] # create image array from paths\n",
    "for path in images_paths:\n",
    "    try: \n",
    "        img = nib.load(path)\n",
    "        image_data = img.get_fdata()\n",
    "        image_array.append(image_data)\n",
    "        final_list.append(path)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "image_array = np.asarray(image_array).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 5 of the 391 images\n",
    "for i in image_array[:5]: \n",
    "    plt.imshow(i[:,:,30])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #??? Ask Chelsea about this line of code. How is this phenotype data? \n",
    "# pheno = df[['FILE_ID', 'DX_GROUP']]\n",
    "# pheno_array = np.array(pheno['DX_GROUP'])\n",
    "# pheno_array = np.where(pheno_array == 2, 0, pheno_array) # This is a function to replace 2 with 0\n",
    "# # distribution\n",
    "# df['DX_GROUP'].value_counts()\n",
    "\n",
    "# I think she means for this to be y label data right?\n",
    "y = df[['FILE_ID', 'DSM_IV_TR', 'SEX_']] # 1 means Autism, 0 means Control\n",
    "#y_array = np.array(y['DSM_IV_TR'])\n",
    "\n",
    "#positive only \n",
    "#y_array = np.array(y.query(\"DSM_IV_TR == 1\")[\"DSM_IV_TR\"])\n",
    "\n",
    "# female only (testing purposes)\n",
    "y_array = np.array(y.query(\"DSM_IV_TR == 1 & SEX_ == 'Female'\")[\"DSM_IV_TR\"])\n",
    "\n",
    "# male only (testing purposes)\n",
    "y_array = np.array(y.query(\"DSM_IV_TR == 1 & SEX_ == 'Male'\")[\"DSM_IV_TR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(image_array, pheno_array, test_size = 0.25, random_state = 44)\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_array, y_array, test_size = 0.25, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking imbalance of training set. Below is how you do value counts for np array. \n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first attempt at plotting \n",
    "#plt.imshow(x_train[:,:,30])\n",
    "#TypeError: Invalid shape (293, 61, 61) for image data\n",
    "\n",
    "#borrowing my other code for plotting\n",
    "for i in x_train[:1]: \n",
    "    plt.imshow(i[30,:,:])\n",
    "    plt.show()\n",
    "    \n",
    "# this code also works\n",
    "plt.imshow(x_train[0][30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_preprocessing(volume, label):\n",
    "#     \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "#     # Rotate volume\n",
    "#     volume = rotate(volume)\n",
    "#     volume = tf.expand_dims(volume, axis=3) #??? Is the extra channel by how much the image was rotated? Ask Dylan.\n",
    "#     return volume, label\n",
    "\n",
    "# def validation_preprocessing(volume, label):\n",
    "#     \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "#     volume = tf.expand_dims(volume, axis=3)\n",
    "#     return volume, label\n",
    "\n",
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1 #return the integer of the division \n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image[30,:,:])\n",
    "        #plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # This is cool, double-check the documentation for this??? \n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test)) #??? Should we have equal number of each class in our training data? \n",
    "\n",
    "batch_size = 16\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train)) # ??? shuffle dubplicates right? Or does it only shuffle? Double-check\n",
    "#     .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE) # ??? I thought prefetch was for speed purposes. What is this tf.data.AUTOTUNE. Double-check. \n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_test))\n",
    "#    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(61 * 73 * 61, input_shape=[codings_size]),\n",
    "    keras.layers.Reshape([61, 73, 61]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv3DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                 activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv3DTranspose(1, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                 activation=\"tanh\"),\n",
    "])\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv3D(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2),\n",
    "                        input_shape=[codings_size]),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Conv3D(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_dcgan = x_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape and rescale\n",
    "X_train_dcgan = x_train.reshape(-1, 61, 73, 61, 1) * 2. - 1. # reshape and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs)) # not shown in the book\n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            #print(noise)\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            #print(X_fake_and_real)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            #print(y1)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1) #??? How does train_on_batch differ from fit? \n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        plot_multiple_images(generated_images, 8) # not shown \n",
    "        #plot_multiple_images(generated_images, 4) # not shown \n",
    "        plt.show() # not shown\n",
    "    return generated_images # Not shown. Trying to figure out where to put this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.8.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
